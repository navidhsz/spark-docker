#spark.authenticate=false
#spark.dynamicAllocation.enabled=true
#spark.dynamicAllocation.executorIdleTimeout=60
#spark.dynamicAllocation.minExecutors=0
#spark.dynamicAllocation.schedulerBacklogTimeout=1
#spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.shuffle.service.enabled = true
spark.shuffle.service.port = 7337
#spark.ui.killEnabled=true
#spark.master=yarn
#spark.submit.deployMode=client
#spark.sql.hive.metastore.jars=${env:HADOOP_COMMON_HOME}/../hive/lib/*:${env:HADOOP_COMMON_HOME}/client/*
#spark.sql.hive.metastore.version=1.1.0
#spark.sql.catalogImplementation=hive

#spark.yarn.jars=local:/opt/cloudera/parcels/SPARK2-2.1.0.cloudera1-1.cdh5.7.0.p0.120904/lib/spark2/jars/*
spark.driver.extraLibraryPath = /opt/cluster/native
spark.executor.extraLibraryPath = /opt/cluster/native
spark.yarn.am.extraLibraryPath = /opt/cluster/native
#spark.hadoop.mapreduce.application.classpath=
#spark.hadoop.yarn.application.classpath=
#spark.yarn.config.gatewayPath=/opt/cloudera/parcels
#spark.yarn.config.replacementPath={{HADOOP_COMMON_HOME}}/../../..

spark.yarn.historyServer.address = 127.0.0.1:18080
spark.eventLog.dir = hdfs://localhost:9000/user/spark/applicationHistory
spark.history.fs.logDirectory = hdfs://localhost:9000/user/spark/applicationHistory
spark.eventLog.enabled = true